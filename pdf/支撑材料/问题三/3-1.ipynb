{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1 = pd.read_excel('data/附件.xlsx',sheet_name='表单1')\n",
    "file2 = pd.read_excel('data/附件.xlsx',sheet_name='表单2')\n",
    "file3 = pd.read_excel('data/附件.xlsx',sheet_name='表单3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 问题三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 68988.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 58/58 [00:00<00:00, 58156.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "tqdm.pandas()\n",
    "\n",
    "def clear_id(s):\n",
    "    ss = str(s)\n",
    "    n = int(re.findall(r\"\\d+\",ss)[0])\n",
    "    return n\n",
    "file2['id'] = file2['文物采样点'].progress_apply(clear_id)\n",
    "file1['id'] = file1['文物编号'].progress_apply(clear_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['表面风化', '二氧化硅(SiO2)',\n",
    "       '氧化钠(Na2O)', '氧化钾(K2O)', '氧化钙(CaO)', '氧化镁(MgO)', '氧化铝(Al2O3)',\n",
    "       '氧化铁(Fe2O3)', '氧化铜(CuO)', '氧化铅(PbO)', '氧化钡(BaO)', '五氧化二磷(P2O5)',\n",
    "       '氧化锶(SrO)', '氧化锡(SnO2)', '二氧化硫(SO2)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = pd.merge(file1,file2,on='id')\n",
    "Gao_data = file_data[file_data['类型']=='高钾'][cols]\n",
    "Qian_data = file_data[file_data['类型']=='铅钡'][cols]\n",
    "test_all = file3[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qian_data = Qian_data.fillna(0)\n",
    "Gao_data = Gao_data.fillna(0)\n",
    "test_all = test_all.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all = pd.concat([Gao_data,Qian_data])\n",
    "encode_data = pd.concat([train_all,test_all])\n",
    "len(train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "all_data = pd.DataFrame() # 用于存放编码后的训练数据\n",
    "label = LabelEncoder() # 标号编码器\n",
    "X= encode_data\n",
    "for c in X.columns: # 对每个特征列\n",
    "    if X[c].dtype=='object': # 如果是字符串形式的(字符串读到pandas里dtype是object)\n",
    "        all_data[c] = label.fit_transform(X[c]) # 将整个这一列进行标号编码，写到新的dataframe里\n",
    "    else: # 其它类型的特征(数值,布尔)保持原样写入\n",
    "        all_data[c] = list(X[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[0:len(train_all)]\n",
    "test = all_data[len(train_all):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # 拆分数据\n",
    "import numpy as np\n",
    "X_var,y_var= train,[0]*len(Gao_data)+[1]*len(Qian_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_var, y_var, test_size = 0.2, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 建立决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as dtc # 树算法\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "model = dtc(criterion = 'entropy', max_depth = 4)\n",
    "model.fit(X_train, y_train)\n",
    "pred_model = model.predict(X_test)\n",
    "print(accuracy_score(y_test, pred_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, pred_model, labels=None, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP值：1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "# 求precision和recall值\n",
    "precision, recall, _ = precision_recall_curve(y_test, pred_model)\n",
    "#求AP值\n",
    "print('AP值：{:.3f}'.format(average_precision_score(y_test, pred_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree # 树图\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "model = dtc(criterion = 'entropy', max_depth = 4)\n",
    "model.fit(X_var, y_var)\n",
    "feature_names = X_var.columns\n",
    "target_names = ['高钾玻璃','铅钡玻璃']\n",
    " \n",
    "plot_tree(model, \n",
    "          feature_names = feature_names, \n",
    "          class_names = target_names, \n",
    "          filled = False, \n",
    "          rounded = True)\n",
    " \n",
    "plt.savefig('./img3/决策树可视化.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree # 树图\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "model = dtc(criterion = 'gini', max_depth = 4)\n",
    "model.fit(X_var, y_var)\n",
    "feature_names = X_var.columns\n",
    "target_names = ['高钾玻璃','铅钡玻璃']\n",
    " \n",
    "plot_tree(model, \n",
    "          feature_names = feature_names, \n",
    "          class_names = target_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果为：高钾,铅钡,铅钡,铅钡,铅钡,高钾,高钾,铅钡\n",
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 判断亚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering #导入sklearn的层次聚类函数\n",
    "df1 = all_data[0:len(Gao_data)]\n",
    "data1 = np.array(df1)\n",
    "gao_test = test.iloc[[0,5,6]]\n",
    "clf1 = AgglomerativeClustering(n_clusters = 3, linkage = 'ward')\n",
    "s = clf1.fit(data1)\n",
    "pred1 = clf1.fit_predict(gao_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering #导入sklearn的层次聚类函数\n",
    "df1 = all_data[len(Gao_data):len(Gao_data)+len(Qian_data)]\n",
    "data1 = np.array(df1)\n",
    "gao_test = test.iloc[[1,2,3,4,7]]\n",
    "clf1 = AgglomerativeClustering(n_clusters = 3, linkage = 'ward')\n",
    "s = clf1.fit(data1)\n",
    "pred1 = clf1.fit_predict(gao_test)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
